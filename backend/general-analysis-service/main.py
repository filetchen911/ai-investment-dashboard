import os
import json
import re
import datetime
import pytz
import firebase_admin
from firebase_admin import firestore
import google.generativeai as genai
from google.api_core import exceptions
import feedparser
import functions_framework
from _version import __version__ # [ç‰ˆæœ¬è™Ÿ] å¼•å…¥ç‰ˆæœ¬è™Ÿ

# --- å¸¸æ•¸è¨­å®š ---
FRESHNESS_THRESHOLD_HOURS = 4 # å¿«å–æœ‰æ•ˆæ™‚é•·ï¼ˆå°æ™‚ï¼‰

# --- åˆå§‹åŒ– ---
try:
    firebase_admin.initialize_app()
    print("âœ… Firebase Admin SDK åˆå§‹åŒ–æˆåŠŸã€‚")
except ValueError:
    print("â„¹ï¸ Firebase App å·²è¢«åˆå§‹åŒ–ï¼Œè·³éã€‚")

def get_finance_news_from_rss(rss_urls):
    # ... (æ­¤è¼”åŠ©å‡½æ•¸é‚è¼¯èˆ‡å…ˆå‰ç‰ˆæœ¬ç›¸åŒ) ...
    print("  > [News Engine] é–‹å§‹æŠ“å– RSS æ–°è...")
    all_news = []
    for rss_url in rss_urls:
        try:
            feed = feedparser.parse(rss_url)
            source_name = feed.feed.title if hasattr(feed.feed, 'title') else 'Unknown Source'
            for entry in feed.entries[:7]:
                if entry.title and entry.link and entry.link not in [n['link'] for n in all_news]:
                    all_news.append({"title": entry.title, "link": entry.link, "source": source_name})
        except Exception as e:
            print(f"    - éŒ¯èª¤ï¼šå¾ {rss_url} ç²å–æ–°èæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    print(f"  > [News Engine] ç¸½å…±å¾ RSS æŠ“å–åˆ° {len(all_news)} æ¢æ–°èã€‚")
    return all_news

def get_latest_economic_data(db_client):
    # ... (æ­¤è¼”åŠ©å‡½æ•¸é‚è¼¯èˆ‡å…ˆå‰ç‰ˆæœ¬ç›¸åŒ) ...
    print("  > [Data Engine] æ­£åœ¨å¾ Firestore ç²å–å®è§€æ•¸æ“š...")
    try:
        query = db_client.collection('daily_economic_data').order_by('date', direction=firestore.Query.DESCENDING).limit(1)
        docs = list(query.stream())
        if docs:
            print("  > [Data Engine] æˆåŠŸç²å–åˆ°å®è§€ç¶“æ¿Ÿæ•¸æ“šã€‚")
            return docs[0].to_dict().get('data_series_items', [])
        print("  > [Data Engine] åœ¨ Firestore ä¸­æœªæ‰¾åˆ°å®è§€ç¶“æ¿Ÿæ•¸æ“šã€‚")
        return []
    except Exception as e:
        print(f"  > [Data Engine] ç²å–ç¶“æ¿Ÿæ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

def analyze_general_market_with_google_ai(economic_data, news_list):
    # ... (æ­¤è¼”åŠ©å‡½æ•¸ç¶“æ”¹é€ ï¼Œä¸å†éœ€è¦ user_assets) ...
    try:
        api_key = os.environ.get("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸ã€‚")

        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash-latest')

        # å°‡å‚³å…¥çš„æ•¸æ“šè½‰æ›ç‚ºç´”æ–‡å­—
        economic_data_text = "\n".join([f"- {item.get('event', 'æœªçŸ¥æŒ‡æ¨™')}: æœ€æ–°æ•¸æ“šç‚º {item['values'][-1]['value']} (æ—¥æœŸ: {item['values'][-1]['date']})" for item in economic_data if item.get('values')]) or "ä»Šæ—¥ç„¡é—œéµå®è§€æ•¸æ“šã€‚"
        news_text = "\n".join([f"{i}. {news.get('title', 'ç„¡æ¨™é¡Œæ–°è')}" for i, news in enumerate(news_list[:15], 1)]) or "ä»Šæ—¥ç„¡ç›¸é—œå¸‚å ´æ–°èã€‚"

        # [æ”¹é€ ] Prompt ç§»é™¤äº†æ‰€æœ‰å€‹äººåŒ–ç›¸é—œçš„å€å¡Š
        prompt = f"""
        ä½ çš„è§’è‰²æ˜¯ä¸€ä½é ‚å°–çš„å®è§€ç¶“æ¿Ÿå­¸å®¶èˆ‡æŠ•è³‡ç­–ç•¥å¸«ã€‚è«‹åš´æ ¼æ ¹æ“šä»¥ä¸‹[ä¸»è¦å®¢è§€æ•¸æ“š]çš„ã€Œè¶¨å‹¢è®ŠåŒ–ã€ï¼Œä¸¦é…Œæƒ…åƒè€ƒ[è¼”åŠ©å¸‚å ´æ–°è]ï¼Œæä¾›ä¸€ä»½ç°¡æ½”ã€å®¢è§€ã€æ•¸æ“šé©…å‹•çš„ä»Šæ—¥å¸‚å ´æ´å¯Ÿã€‚

        [ä¸»è¦å®¢è§€æ•¸æ“š]
        {economic_data_text}

        [è¼”åŠ©å¸‚å ´æ–°è]
        {news_text}

        è«‹ä¾æ“šä»¥ä¸Šæ‰€æœ‰è³‡è¨Šï¼Œæä¾›ä¸€ä»½åš´æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼çš„ JSON å ±å‘Šï¼š
        {{
          "market_summary": "åŸºæ–¼ä»Šæ—¥æ•¸æ“šã€Œè¶¨å‹¢ã€çš„æ•´é«”å¸‚å ´æƒ…ç·’ç¸½çµã€‚",
          "key_takeaways": [
            {{
              "type": "æ•¸æ“šæ´è¦‹",
              "content": "å¾ä»Šå¤©æœ€é‡è¦çš„1-2å€‹æ•¸æ“šçš„ã€Œè¶¨å‹¢ã€ä¸­ï¼Œæç…‰å‡ºçš„æ ¸å¿ƒæ´è¦‹ã€‚",
              "source": "FRED API"
            }},
            {{
              "type": "æ–°èæ´è¦‹",
              "content": "å¾ä»Šå¤©æœ€ç›¸é—œçš„1-2æ¢æ–°èä¸­ï¼Œæç…‰å‡ºçš„æ ¸å¿ƒæ´è¦‹ã€‚",
              "source": "æ–°èä¾†æºç¶²ç«™å"
            }}
          ]
        }}
        """

        response = model.generate_content(prompt)
        raw_response = response.text
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
        cleaned_response = json_match.group(1) if json_match else raw_response
        return json.loads(cleaned_response)

    except Exception as e:
        print(f"âŒ åœ¨å‘¼å« Google AI æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        # å°‡éŒ¯èª¤å›å‚³ï¼Œä»¥ä¾¿ HTTP éŸ¿æ‡‰èƒ½åæ˜ å‡ºä¾†
        raise

@functions_framework.http
def generate_general_analysis(request):
    """
    [v5.2.0] ç”±å‰ç«¯ HTTP è«‹æ±‚è§¸ç™¼ï¼Œå…§å«æ™ºæ…§å¿«å–æª¢æŸ¥ã€‚
    """
    print(f"--- é€šç”¨å¸‚å ´åˆ†ææœå‹™ (v{__version__}) é–‹å§‹åŸ·è¡Œ ---")
    db = firestore.client()
    doc_id = datetime.datetime.now(pytz.timezone('Asia/Taipei')).strftime("%Y-%m-%d")
    doc_ref = db.collection('general_analysis').document(doc_id)

    # --- [v5.2.0 æ™ºæ…§å¿«å–æª¢æŸ¥] ---
    try:
        doc = doc_ref.get()
        if doc.exists:
            data = doc.to_dict()
            last_updated_utc = data.get('last_updated').replace(tzinfo=pytz.UTC) # ç¢ºä¿æ™‚é–“æ˜¯ UTC aware
            now_utc = datetime.datetime.now(pytz.UTC)
            time_difference = now_utc - last_updated_utc
            
            if time_difference.total_seconds() / 3600 < FRESHNESS_THRESHOLD_HOURS:
                print(f"âœ… å¿«å–å‘½ä¸­ï¼šæ‰¾åˆ° {FRESHNESS_THRESHOLD_HOURS} å°æ™‚å…§çš„æ–°é®®å ±å‘Šã€‚ç›´æ¥å›å‚³å¿«å–å…§å®¹ã€‚")
                return {"status": "success_from_cache", "version": __version__, "doc_id": doc_id, "data": data}, 200
            else:
                print(f"ğŸŸ¡ å¿«å–éæ™‚ï¼šæ‰¾åˆ°ä»Šæ—¥å ±å‘Šï¼Œä½†å·²è¶…é {FRESHNESS_THRESHOLD_HOURS} å°æ™‚ã€‚ç¹¼çºŒåŸ·è¡Œä»¥ç”¢ç”Ÿæ–°å ±å‘Šã€‚")
        else:
            print(f"â„¹ï¸ å¿«å–æœªå‘½ä¸­ï¼šä»Šæ—¥å°šç„¡åˆ†æå ±å‘Šã€‚ç¹¼çºŒåŸ·è¡Œä»¥ç”¢ç”Ÿæ–°å ±å‘Šã€‚")
            
    except Exception as e:
        print(f"âš ï¸ è®€å–å¿«å–æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}ã€‚ç¹¼çºŒåŸ·è¡Œä»¥ç”¢ç”Ÿæ–°å ±å‘Šã€‚")
    # --- [æª¢æŸ¥çµæŸ] ---

    try:
        # 1. æŠ“å–é€šç”¨æ•¸æ“š (æ–°è & ç¶“æ¿ŸæŒ‡æ¨™)
        # [ä¿®æ­£] æ¡ç”¨æ‚¨æŒ‡å®šçš„å®Œæ•´æ–°èä¾†æºåˆ—è¡¨
        print("  > [æ–°å ±å‘Šç”¢ç”Ÿæµç¨‹] é–‹å§‹æŠ“å–é€šç”¨æ•¸æ“š...")
        rss_urls = [
            "https://www.macromicro.me/rss/cn/research", "https://technews.tw/feed/",
            "https://feeds.bloomberg.com/bview/rss.xml",
            "https://news.google.com/rss/search?q=when:1d+å°è‚¡&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
            "https://news.google.com/rss/search?q=when:1d+ç¾è‚¡&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
        ]

        raw_news_list = get_finance_news_from_rss(rss_urls)
        latest_economic_data = get_latest_economic_data(db)

        # 2. å‘¼å« AI é€²è¡Œä¸€æ¬¡æ€§çš„é€šç”¨åˆ†æ
        print("  > [æ–°å ±å‘Šç”¢ç”Ÿæµç¨‹] å‘¼å« Google AI é€²è¡Œåˆ†æ...")
        general_analysis_result = analyze_general_market_with_google_ai(latest_economic_data, raw_news_list)

        if not general_analysis_result:
             return {"status": "error", "message": "æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„ AI åˆ†æçµæœã€‚"}, 500

        # 3. ç‚ºç”¢ç”Ÿçš„çµæœåŠ ä¸Š TTL åˆ°æœŸæ™‚é–“èˆ‡ç‰ˆæœ¬è™Ÿ
        print("  > [æ–°å ±å‘Šç”¢ç”Ÿæµç¨‹] æº–å‚™å°‡çµæœå¯«å…¥ Firestore...")
        # æº–å‚™å¯«å…¥ Firestore çš„è³‡æ–™
        expire_at_time = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(days=7)
        data_for_firestore = {
            "last_updated": firestore.SERVER_TIMESTAMP, # <-- åŒ…å« Sentinel
            "expireAt": expire_at_time, # <-- åŒ…å« datetime ç‰©ä»¶
            "version": __version__,
            **general_analysis_result # è§£æ§‹ AI åˆ†æçµæœ
        }

        # å°‡åŒ…å«ç‰¹æ®Šç‰©ä»¶çš„è³‡æ–™å¯«å…¥ Firestore
        doc_ref.set(data_for_firestore)

        
        print(f"âœ… [æ–°å ±å‘Š] é€šç”¨å¸‚å ´åˆ†æçµæœå·²æˆåŠŸå¯«å…¥ Firestore: {doc_id}")

        # --- [v5.2.0-rc6 ä¿®æ­£] ---
        # æº–å‚™ä¸€å€‹ã€Œä¹¾æ·¨ã€çš„ç‰ˆæœ¬å›å‚³çµ¦å‰ç«¯
        response_data = data_for_firestore.copy()
        
        # å°‡ Firestore Sentinel å’Œ datetime ç‰©ä»¶è½‰æ›ç‚º JSON ç›¸å®¹çš„ ISO æ ¼å¼å­—ä¸²
        response_data['last_updated'] = datetime.datetime.now(datetime.timezone.utc).isoformat()
        response_data['expireAt'] = expire_at_time.isoformat()
        
        return {"status": "success_newly_generated", "version": __version__, "doc_id": doc_id, "data": response_data}, 200
        # --- [ä¿®æ­£çµæŸ] ---

    except Exception as e:
        print(f"âŒ å‡½å¼åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        return {"status": "error", "version": __version__, "message": str(e)}, 500