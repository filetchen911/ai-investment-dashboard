# file: pages/50_ai_insights.py
# version: v5.5.0 (èˆ‡ç¾æœ‰æ‡‰ç”¨æ¡†æ¶å®Œå…¨ç›¸å®¹)

import streamlit as st
import pytz
from datetime import datetime
from utils import (
    render_sidebar,
    init_firebase,
    get_general_analysis_status,
    trigger_general_analysis
)

# éµå¾ªç¾æœ‰é é¢æ¨¡å¼ï¼šé¦–å…ˆæ¸²æŸ“å´é‚Šæ¬„
render_sidebar()

# éµå¾ªç¾æœ‰é é¢æ¨¡å¼ï¼šè¨­å®šé é¢æ¨™é¡Œ
st.set_page_config(layout="wide")
st.title("ğŸ’¡ AI æ¯æ—¥å¸‚å ´æ´å¯Ÿ")
st.caption("æ­¤é é¢æä¾›ç”±å¤§å‹èªè¨€æ¨¡å‹(LLM)ç”Ÿæˆçš„æ¯æ—¥é€šç”¨å¸‚å ´åˆ†æï¼Œæ•´åˆäº†å®è§€æ•¸æ“šèˆ‡é‡åŒ–æ¨¡å‹ï¼Œä»¥æä¾›å®¢è§€çš„å¸‚å ´æ´å¯Ÿã€‚")

# éµå¾ªç¾æœ‰é é¢æ¨¡å¼ï¼šé€²è¡Œèº«ä»½é©—è­‰æª¢æŸ¥
if 'user_id' not in st.session_state:
    st.info("è«‹å…ˆå¾ä¸»é é¢ç™»å…¥ï¼Œä»¥ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚")
    st.stop()

# éµå¾ªç¾æœ‰é é¢æ¨¡å¼ï¼šåˆå§‹åŒ–å¿…è¦çš„è®Šæ•¸
user_id = st.session_state['user_id']
db, _ = init_firebase()

# --------------------------------------------------------------------------------
# é¡¯ç¤ºå ±å‘Šå°ˆç”¨çš„å‡½å¼ (é€™æ˜¯ä¸€å€‹ç¨ç«‹çš„è¼”åŠ©å‡½å¼ï¼Œå¯ä»¥å®‰å…¨åœ°æ”¾åœ¨æª”æ¡ˆé ‚éƒ¨)
# --------------------------------------------------------------------------------
def display_analysis_report(data: dict):
    """
    å°ˆé–€ç”¨ä¾†æ¸²æŸ“æ–°ç‰ˆ AI åˆ†æå ±å‘Šçš„å‡½å¼
    """
    # --- å€å¡Š 1: å ±å‘Šæ¨™é¡Œèˆ‡æ•´é«”æƒ…ç·’ ---
    st.subheader(data.get("report_title", "ä»Šæ—¥å¸‚å ´åˆ†æ"))

    sentiment_map = {
        "æ¨‚è§€": "ğŸ”¥", "è¬¹æ…æ¨‚è§€": "ğŸŸ¢", "ä¸­æ€§": "âšª",
        "è¬¹æ…æ‚²è§€": "ğŸŸ ", "æ‚²è§€": "ğŸ¥¶"
    }
    sentiment_icon = sentiment_map.get(data.get("overall_sentiment"), "â“")
    st.metric(label="å¸‚å ´æ•´é«”æƒ…ç·’", value=f"{sentiment_icon} {data.get('overall_sentiment', 'æœªçŸ¥')}")

    st.divider()

    # --- å€å¡Š 2: åˆ†ææ‘˜è¦ ---
    st.markdown("##### ğŸ“ˆ åˆ†ææ‘˜è¦")
    st.write(data.get("analysis_summary", "æ‘˜è¦å…§å®¹ç¼ºå¤±ã€‚"))

    st.divider()

    # --- å€å¡Š 3: æ­£åæ–¹å› å­ (ä½¿ç”¨é›™æ¬„ä½ˆå±€) ---
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("##### âœ… æ­£é¢æ”¯æ’å› å­")
        positive_factors = data.get("positive_factors", [])
        if not positive_factors:
            st.info("å ±å‘Šä¸­æœªæåŠä¸»è¦çš„æ­£é¢å› å­ã€‚")
        else:
            for factor in positive_factors:
                with st.expander(f"**{factor.get('factor', 'æœªçŸ¥å› å­')}**", expanded=True):
                    st.markdown(f"**- è­‰æ“š:** {factor.get('evidence', 'ç„¡')}")
                    st.markdown(f"**- å½±éŸ¿:** {factor.get('implication', 'ç„¡')}")

    with col2:
        st.markdown("##### âš ï¸ æ½›åœ¨é¢¨éšªå› å­")
        risk_factors = data.get("risk_factors", [])
        if not risk_factors:
            st.info("å ±å‘Šä¸­æœªæåŠä¸»è¦çš„é¢¨éšªå› å­ã€‚")
        else:
            for factor in risk_factors:
                with st.expander(f"**{factor.get('factor', 'æœªçŸ¥å› å­')}**", expanded=True):
                    st.markdown(f"**- è­‰æ“š:** {factor.get('evidence', 'ç„¡')}")
                    st.markdown(f"**- å½±éŸ¿:** {factor.get('implication', 'ç„¡')}")

    st.divider()

    # --- å€å¡Š 4: æŠ•è³‡çµè«– ---
    st.markdown("##### ğŸ§­ æŠ•è³‡çµè«–")
    st.info(data.get("investment_conclusion", "çµè«–å…§å®¹ç¼ºå¤±ã€‚"), icon="ğŸ’¡")

# --------------------------------------------------------------------------------
# é é¢ä¸»é«”é‚è¼¯ (ç›´æ¥åœ¨é ‚å±¤åŸ·è¡Œï¼Œä¸ä½¿ç”¨ main() å‡½å¼)
# --------------------------------------------------------------------------------

# ä½¿ç”¨ utils ä¸­çš„å‡½å¼æª¢æŸ¥å¿«å–ç‹€æ…‹
with st.spinner("æ­£åœ¨æª¢æŸ¥æœ€æ–°çš„ AI æ´å¯Ÿå ±å‘Š..."):
    analysis_status = get_general_analysis_status()

# æƒ…æ³ä¸€: å ±å‘Šå·²å­˜åœ¨
if analysis_status.get("exists") and analysis_status.get("data"):
    report_data = analysis_status["data"]

    # é¡¯ç¤ºå ±å‘Šæ›´æ–°æ™‚é–“
    try:
        last_updated_raw = report_data.get('last_updated')
        if isinstance(last_updated_raw, str):
            last_updated_utc = datetime.fromisoformat(last_updated_raw.replace('Z', '+00:00'))
        else:
            last_updated_utc = last_updated_raw.replace(tzinfo=pytz.UTC)
        
        taipei_tz = pytz.timezone("Asia/Taipei")
        last_updated_taipei = last_updated_utc.astimezone(taipei_tz)
        st.caption(f"ä¸Šæ¬¡åˆ†ææ™‚é–“: {last_updated_taipei.strftime('%Y-%m-%d %H:%M:%S')} (å°åŒ—æ™‚é–“)")
    except Exception:
        # å¦‚æœæ™‚é–“è§£æå¤±æ•—ï¼Œå„ªé›…åœ°è·³é
        pass

    # å‘¼å«å°ˆç”¨å‡½å¼ä¾†é¡¯ç¤ºå ±å‘Š
    display_analysis_report(report_data)

    st.divider()

    # æä¾›ä¸€å€‹æ‰‹å‹•åˆ·æ–°çš„æŒ‰éˆ•
    if st.button("ğŸ”„ å¼·åˆ¶åˆ·æ–°åˆ†æå ±å‘Š"):
        with st.spinner("æ­£åœ¨å¼·åˆ¶è§¸ç™¼å¾Œç«¯åˆ†ææœå‹™ï¼Œè«‹ç¨å€™..."):
            success = trigger_general_analysis()
            if success:
                st.success("åˆ·æ–°è«‹æ±‚å·²é€å‡ºï¼é é¢å°‡åœ¨å¹¾ç§’å¾Œè‡ªå‹•é‡è¼‰ä»¥ç²å–æœ€æ–°å ±å‘Šã€‚")
                st.cache_data.clear() # æ¸…é™¤å‰ç«¯å¿«å–
                st.rerun()
            else:
                st.error("åˆ·æ–°å¤±æ•—ï¼Œè«‹æª¢æŸ¥å¾Œç«¯æœå‹™æ—¥èªŒã€‚")

# æƒ…æ³äºŒ: å ±å‘Šä¸å­˜åœ¨
else:
    st.info("ä»Šæ—¥å°šç„¡é€šç”¨å¸‚å ´åˆ†æå ±å‘Šã€‚æ‚¨å¯ä»¥é»æ“Šä¸‹æ–¹æŒ‰éˆ•ç«‹å³ç”¢ç”Ÿã€‚")
    if st.button("ğŸš€ ç”¢ç”Ÿä»Šæ—¥å¸‚å ´æ´å¯Ÿå ±å‘Š"):
        with st.spinner("é¦–æ¬¡ç”¢ç”Ÿå ±å‘Šéœ€è¦ç´„ 1-2 åˆ†é˜ï¼Œè«‹è€å¿ƒç­‰å€™..."):
            success = trigger_general_analysis()
            if success:
                st.success("å ±å‘Šå·²æˆåŠŸç”Ÿæˆï¼é é¢å°‡è‡ªå‹•åˆ·æ–°ã€‚")
                st.cache_data.clear() # æ¸…é™¤å‰ç«¯å¿«å–
                st.rerun()
            else:
                st.error("å ±å‘Šç”Ÿæˆå¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦æˆ–è¯ç¹«ç®¡ç†å“¡ã€‚")